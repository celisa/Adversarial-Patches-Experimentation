{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/codespace/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "vgg_model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg16_bn') # batch normalized\n",
    "vgg_model = vgg_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# preapre data\n",
    "\n",
    "# PARAMS\n",
    "batch_size = 256\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "target = 1 #automobile\n",
    "\n",
    "#CIFAR-10 image tensor mean and std\n",
    "NORM_MEAN = [0.4914, 0.4822, 0.4465]\n",
    "NORM_STD = [0.2023, 0.1994, 0.2010]\n",
    "\n",
    "\n",
    "# TODO: should we apply the below transformations?\n",
    "transform_train = transforms.Compose([\n",
    "    #transforms.RandomCrop(32, padding=4),\n",
    "    #transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=NORM_MEAN,\n",
    "                         std=NORM_STD)\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=NORM_MEAN,\n",
    "                         std=NORM_STD)\n",
    "])\n",
    "\n",
    "transform_image = transforms.ToPILImage()\n",
    "\n",
    "print('==> Preparing data..')\n",
    "trainset = torchvision.datasets.CIFAR10(root='../../00_data/', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='../../00_data/', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finetune on CIFAR-10 data\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def train(net, epochs, batch_size, lr, reg, log_every_n=50, trainloader=None, testloader=None):\n",
    "    \"\"\"\n",
    "    Training a network\n",
    "    :param net: Network for training\n",
    "    :param epochs: Number of epochs in total.\n",
    "    :param batch_size: Batch size for training.\n",
    "    \"\"\"\n",
    "    print('==> Preparing data..')\n",
    "\n",
    "    best_acc = 0  # best test accuracy\n",
    "    start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.875, weight_decay=reg, nesterov=False)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[int(epochs*0.5), int(epochs*0.75)], gamma=0.1)\n",
    "\n",
    "    global_steps = 0\n",
    "    start = time.time()\n",
    "\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        \"\"\"\n",
    "        Start the training code.\n",
    "        \"\"\"\n",
    "        print('\\nEpoch: %d' % epoch)\n",
    "        net.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            global_steps += 1\n",
    "\n",
    "            if global_steps % log_every_n == 0:\n",
    "                end = time.time()\n",
    "                num_examples_per_second = log_every_n * batch_size / (end - start)\n",
    "                print(\"[Step=%d]\\tLoss=%.4f\\tacc=%.4f\\t%.1f examples/second\"\n",
    "                      % (global_steps, train_loss / (batch_idx + 1), (correct / total), num_examples_per_second))\n",
    "                start = time.time()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        \"\"\"\n",
    "        Start the testing code.\n",
    "        \"\"\"\n",
    "        net.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "        num_val_steps = len(testloader)\n",
    "        val_acc = correct / total\n",
    "        print(\"Test Loss=%.4f, Test acc=%.4f\" % (test_loss / (num_val_steps), val_acc))\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            print(\"Saving...\")\n",
    "            torch.save(net.state_dict(), \"pretrained_vgg_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Attempt to open cnn_infer failed: handle=0 error: libcudnn_cnn_infer.so.8: cannot open shared object file: No such file or directory (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:78.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step=50]\tLoss=2.8571\tacc=0.1417\t3245.9 examples/second\n",
      "[Step=100]\tLoss=2.4105\tacc=0.2036\t3803.1 examples/second\n",
      "[Step=150]\tLoss=2.1927\tacc=0.2471\t3806.9 examples/second\n",
      "Test Loss=1.5019, Test acc=0.4417\n",
      "Saving...\n",
      "\n",
      "Epoch: 1\n",
      "[Step=200]\tLoss=1.5595\tacc=0.4277\t2142.1 examples/second\n",
      "[Step=250]\tLoss=1.5106\tacc=0.4347\t3799.0 examples/second\n",
      "[Step=300]\tLoss=1.4944\tacc=0.4419\t3784.1 examples/second\n",
      "[Step=350]\tLoss=1.4609\tacc=0.4562\t3791.3 examples/second\n",
      "Test Loss=1.3365, Test acc=0.5164\n",
      "Saving...\n",
      "\n",
      "Epoch: 2\n",
      "[Step=400]\tLoss=1.3009\tacc=0.5322\t1978.9 examples/second\n",
      "[Step=450]\tLoss=1.2745\tacc=0.5294\t3792.8 examples/second\n",
      "[Step=500]\tLoss=1.2573\tacc=0.5389\t3797.9 examples/second\n",
      "[Step=550]\tLoss=1.2367\tacc=0.5486\t3797.1 examples/second\n",
      "Test Loss=1.1745, Test acc=0.5790\n",
      "Saving...\n",
      "\n",
      "Epoch: 3\n",
      "[Step=600]\tLoss=1.1184\tacc=0.5947\t2000.2 examples/second\n",
      "[Step=650]\tLoss=1.0672\tacc=0.6132\t3787.5 examples/second\n",
      "[Step=700]\tLoss=1.0583\tacc=0.6169\t3805.7 examples/second\n",
      "[Step=750]\tLoss=1.0517\tacc=0.6208\t3800.1 examples/second\n",
      "Test Loss=1.1267, Test acc=0.5977\n",
      "Saving...\n",
      "\n",
      "Epoch: 4\n",
      "[Step=800]\tLoss=0.9007\tacc=0.6799\t1972.8 examples/second\n",
      "[Step=850]\tLoss=0.9119\tacc=0.6726\t3779.1 examples/second\n",
      "[Step=900]\tLoss=0.9007\tacc=0.6771\t3802.1 examples/second\n",
      "[Step=950]\tLoss=0.9001\tacc=0.6764\t3806.6 examples/second\n",
      "Test Loss=1.1543, Test acc=0.6045\n",
      "Saving...\n",
      "\n",
      "Epoch: 5\n",
      "[Step=1000]\tLoss=0.7591\tacc=0.7299\t1995.1 examples/second\n",
      "[Step=1050]\tLoss=0.7505\tacc=0.7275\t3790.8 examples/second\n",
      "[Step=1100]\tLoss=0.7526\tacc=0.7287\t3785.5 examples/second\n",
      "[Step=1150]\tLoss=0.7601\tacc=0.7264\t3799.5 examples/second\n",
      "Test Loss=1.0798, Test acc=0.6341\n",
      "Saving...\n",
      "\n",
      "Epoch: 6\n",
      "[Step=1200]\tLoss=0.6321\tacc=0.7767\t2013.4 examples/second\n",
      "[Step=1250]\tLoss=0.6140\tacc=0.7832\t3771.8 examples/second\n",
      "[Step=1300]\tLoss=0.6184\tacc=0.7805\t3792.1 examples/second\n",
      "[Step=1350]\tLoss=0.6248\tacc=0.7765\t3799.9 examples/second\n",
      "Test Loss=1.1215, Test acc=0.6415\n",
      "Saving...\n",
      "\n",
      "Epoch: 7\n",
      "[Step=1400]\tLoss=0.4940\tacc=0.8253\t1992.3 examples/second\n",
      "[Step=1450]\tLoss=0.4878\tacc=0.8259\t3770.8 examples/second\n",
      "[Step=1500]\tLoss=0.4886\tacc=0.8246\t3790.1 examples/second\n",
      "[Step=1550]\tLoss=0.4948\tacc=0.8220\t3808.5 examples/second\n",
      "Test Loss=1.2205, Test acc=0.6337\n",
      "\n",
      "Epoch: 8\n",
      "[Step=1600]\tLoss=0.3616\tacc=0.8716\t2456.8 examples/second\n",
      "[Step=1650]\tLoss=0.3598\tacc=0.8736\t3793.2 examples/second\n",
      "[Step=1700]\tLoss=0.3661\tacc=0.8702\t3782.4 examples/second\n",
      "[Step=1750]\tLoss=0.3716\tacc=0.8675\t3791.0 examples/second\n",
      "Test Loss=1.2794, Test acc=0.6427\n",
      "Saving...\n",
      "\n",
      "Epoch: 9\n",
      "[Step=1800]\tLoss=0.2683\tacc=0.9090\t1960.6 examples/second\n",
      "[Step=1850]\tLoss=0.2597\tacc=0.9083\t3776.6 examples/second\n",
      "[Step=1900]\tLoss=0.2646\tacc=0.9058\t3796.2 examples/second\n",
      "[Step=1950]\tLoss=0.2767\tacc=0.9010\t3800.0 examples/second\n",
      "Test Loss=1.4577, Test acc=0.6359\n",
      "\n",
      "Epoch: 10\n",
      "[Step=2000]\tLoss=0.1771\tacc=0.9401\t2449.8 examples/second\n",
      "[Step=2050]\tLoss=0.1564\tacc=0.9497\t3793.7 examples/second\n",
      "[Step=2100]\tLoss=0.1444\tacc=0.9545\t3790.0 examples/second\n",
      "[Step=2150]\tLoss=0.1365\tacc=0.9578\t3781.6 examples/second\n",
      "Test Loss=1.3188, Test acc=0.6710\n",
      "Saving...\n",
      "\n",
      "Epoch: 11\n",
      "[Step=2200]\tLoss=0.0901\tacc=0.9751\t1570.2 examples/second\n",
      "[Step=2250]\tLoss=0.0868\tacc=0.9764\t3796.7 examples/second\n",
      "[Step=2300]\tLoss=0.0845\tacc=0.9774\t3794.5 examples/second\n",
      "[Step=2350]\tLoss=0.0836\tacc=0.9778\t3803.1 examples/second\n",
      "Test Loss=1.3733, Test acc=0.6673\n",
      "\n",
      "Epoch: 12\n",
      "[Step=2400]\tLoss=0.0658\tacc=0.9849\t2425.9 examples/second\n",
      "[Step=2450]\tLoss=0.0649\tacc=0.9852\t3741.2 examples/second\n",
      "[Step=2500]\tLoss=0.0655\tacc=0.9846\t3787.9 examples/second\n",
      "Test Loss=1.4178, Test acc=0.6690\n",
      "\n",
      "Epoch: 13\n",
      "[Step=2550]\tLoss=0.0579\tacc=0.9824\t2408.6 examples/second\n",
      "[Step=2600]\tLoss=0.0507\tacc=0.9906\t3793.1 examples/second\n",
      "[Step=2650]\tLoss=0.0515\tacc=0.9905\t3792.5 examples/second\n",
      "[Step=2700]\tLoss=0.0509\tacc=0.9903\t3794.7 examples/second\n",
      "Test Loss=1.4607, Test acc=0.6673\n",
      "\n",
      "Epoch: 14\n",
      "[Step=2750]\tLoss=0.0411\tacc=0.9935\t2431.7 examples/second\n",
      "[Step=2800]\tLoss=0.0455\tacc=0.9920\t3786.8 examples/second\n",
      "[Step=2850]\tLoss=0.0445\tacc=0.9924\t3794.7 examples/second\n",
      "[Step=2900]\tLoss=0.0438\tacc=0.9923\t3796.9 examples/second\n",
      "Test Loss=1.4929, Test acc=0.6681\n",
      "\n",
      "Epoch: 15\n",
      "[Step=2950]\tLoss=0.0417\tacc=0.9934\t2447.4 examples/second\n",
      "[Step=3000]\tLoss=0.0377\tacc=0.9938\t3797.8 examples/second\n",
      "[Step=3050]\tLoss=0.0386\tacc=0.9934\t3795.3 examples/second\n",
      "[Step=3100]\tLoss=0.0381\tacc=0.9937\t3782.3 examples/second\n",
      "Test Loss=1.4980, Test acc=0.6698\n",
      "\n",
      "Epoch: 16\n",
      "[Step=3150]\tLoss=0.0318\tacc=0.9953\t2435.2 examples/second\n",
      "[Step=3200]\tLoss=0.0332\tacc=0.9948\t3793.7 examples/second\n",
      "[Step=3250]\tLoss=0.0342\tacc=0.9948\t3782.0 examples/second\n",
      "[Step=3300]\tLoss=0.0343\tacc=0.9946\t3782.2 examples/second\n",
      "Test Loss=1.5033, Test acc=0.6696\n",
      "\n",
      "Epoch: 17\n",
      "[Step=3350]\tLoss=0.0345\tacc=0.9937\t2410.0 examples/second\n",
      "[Step=3400]\tLoss=0.0338\tacc=0.9948\t3769.6 examples/second\n",
      "[Step=3450]\tLoss=0.0343\tacc=0.9944\t3789.6 examples/second\n",
      "[Step=3500]\tLoss=0.0347\tacc=0.9944\t3775.3 examples/second\n",
      "Test Loss=1.5016, Test acc=0.6680\n",
      "\n",
      "Epoch: 18\n",
      "[Step=3550]\tLoss=0.0329\tacc=0.9945\t2450.9 examples/second\n",
      "[Step=3600]\tLoss=0.0335\tacc=0.9941\t3781.0 examples/second\n",
      "[Step=3650]\tLoss=0.0339\tacc=0.9940\t3788.5 examples/second\n",
      "[Step=3700]\tLoss=0.0342\tacc=0.9942\t3786.7 examples/second\n",
      "Test Loss=1.5075, Test acc=0.6669\n",
      "\n",
      "Epoch: 19\n",
      "[Step=3750]\tLoss=0.0320\tacc=0.9962\t2356.3 examples/second\n",
      "[Step=3800]\tLoss=0.0342\tacc=0.9947\t3801.1 examples/second\n",
      "[Step=3850]\tLoss=0.0337\tacc=0.9945\t3795.4 examples/second\n",
      "[Step=3900]\tLoss=0.0328\tacc=0.9950\t3776.0 examples/second\n",
      "Test Loss=1.5169, Test acc=0.6682\n"
     ]
    }
   ],
   "source": [
    "train(vgg_model, 20, batch_size, 0.001, 0.0005, trainloader=trainloader, testloader=testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
