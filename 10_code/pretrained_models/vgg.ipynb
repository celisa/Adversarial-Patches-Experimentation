{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/codespace/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "vgg_model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg16_bn') # batch normalized\n",
    "vgg_model = vgg_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# preapre data\n",
    "\n",
    "# PARAMS\n",
    "batch_size = 256\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "target = 1 #automobile\n",
    "\n",
    "#CIFAR-10 image tensor mean and std\n",
    "NORM_MEAN = [0.4914, 0.4822, 0.4465]\n",
    "NORM_STD = [0.2023, 0.1994, 0.2010]\n",
    "\n",
    "\n",
    "# TODO: should we apply the below transformations?\n",
    "transform_train = transforms.Compose([\n",
    "    #transforms.RandomCrop(32, padding=4),\n",
    "    #transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=NORM_MEAN,\n",
    "                         std=NORM_STD)\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=NORM_MEAN,\n",
    "                         std=NORM_STD)\n",
    "])\n",
    "\n",
    "transform_image = transforms.ToPILImage()\n",
    "\n",
    "print('==> Preparing data..')\n",
    "trainset = torchvision.datasets.CIFAR10(root='../../00_data/', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='../../00_data/', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finetune on CIFAR-10 data\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def train(net, epochs, batch_size, lr, reg, log_every_n=50, trainloader=None, testloader=None):\n",
    "    \"\"\"\n",
    "    Training a network\n",
    "    :param net: Network for training\n",
    "    :param epochs: Number of epochs in total.\n",
    "    :param batch_size: Batch size for training.\n",
    "    \"\"\"\n",
    "    print('==> Preparing data..')\n",
    "\n",
    "    best_acc = 0  # best test accuracy\n",
    "    start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.875, weight_decay=reg, nesterov=False)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[int(epochs*0.5), int(epochs*0.75)], gamma=0.1)\n",
    "\n",
    "    global_steps = 0\n",
    "    start = time.time()\n",
    "\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        \"\"\"\n",
    "        Start the training code.\n",
    "        \"\"\"\n",
    "        print('\\nEpoch: %d' % epoch)\n",
    "        net.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            global_steps += 1\n",
    "\n",
    "            if global_steps % log_every_n == 0:\n",
    "                end = time.time()\n",
    "                num_examples_per_second = log_every_n * batch_size / (end - start)\n",
    "                print(\"[Step=%d]\\tLoss=%.4f\\tacc=%.4f\\t%.1f examples/second\"\n",
    "                      % (global_steps, train_loss / (batch_idx + 1), (correct / total), num_examples_per_second))\n",
    "                start = time.time()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        \"\"\"\n",
    "        Start the testing code.\n",
    "        \"\"\"\n",
    "        net.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "        num_val_steps = len(testloader)\n",
    "        val_acc = correct / total\n",
    "        print(\"Test Loss=%.4f, Test acc=%.4f\" % (test_loss / (num_val_steps), val_acc))\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            print(\"Saving...\")\n",
    "            torch.save(net.state_dict(), \"pretrained_vgg_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Attempt to open cnn_infer failed: handle=0 error: libcudnn_cnn_infer.so.8: cannot open shared object file: No such file or directory (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:78.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step=50]\tLoss=2.8122\tacc=0.1398\t3272.5 examples/second\n",
      "[Step=100]\tLoss=2.3698\tacc=0.2061\t3807.1 examples/second\n",
      "[Step=150]\tLoss=2.1596\tacc=0.2510\t3805.0 examples/second\n",
      "Test Loss=1.4888, Test acc=0.4446\n",
      "Saving...\n",
      "\n",
      "Epoch: 1\n",
      "[Step=200]\tLoss=1.5435\tacc=0.4258\t2131.1 examples/second\n",
      "[Step=250]\tLoss=1.5084\tacc=0.4374\t3796.6 examples/second\n",
      "[Step=300]\tLoss=1.4804\tacc=0.4501\t3811.8 examples/second\n",
      "[Step=350]\tLoss=1.4530\tacc=0.4609\t3811.2 examples/second\n",
      "Test Loss=1.3034, Test acc=0.5255\n",
      "Saving...\n",
      "\n",
      "Epoch: 2\n",
      "[Step=400]\tLoss=1.2662\tacc=0.5288\t1984.7 examples/second\n",
      "[Step=450]\tLoss=1.2396\tacc=0.5432\t3801.2 examples/second\n",
      "[Step=500]\tLoss=1.2316\tacc=0.5474\t3809.5 examples/second\n",
      "[Step=550]\tLoss=1.2206\tacc=0.5529\t3809.2 examples/second\n",
      "Test Loss=1.1825, Test acc=0.5773\n",
      "Saving...\n",
      "\n",
      "Epoch: 3\n",
      "[Step=600]\tLoss=1.1136\tacc=0.5957\t1998.9 examples/second\n",
      "[Step=650]\tLoss=1.0611\tacc=0.6150\t3757.7 examples/second\n",
      "[Step=700]\tLoss=1.0642\tacc=0.6125\t3808.2 examples/second\n",
      "[Step=750]\tLoss=1.0591\tacc=0.6148\t3813.5 examples/second\n",
      "Test Loss=1.1025, Test acc=0.6111\n",
      "Saving...\n",
      "\n",
      "Epoch: 4\n",
      "[Step=800]\tLoss=0.8942\tacc=0.6860\t2009.2 examples/second\n",
      "[Step=850]\tLoss=0.8992\tacc=0.6768\t3799.4 examples/second\n",
      "[Step=900]\tLoss=0.9010\tacc=0.6768\t3804.3 examples/second\n",
      "[Step=950]\tLoss=0.9041\tacc=0.6758\t3815.4 examples/second\n",
      "Test Loss=1.1204, Test acc=0.6141\n",
      "Saving...\n",
      "\n",
      "Epoch: 5\n",
      "[Step=1000]\tLoss=0.7804\tacc=0.7211\t1816.3 examples/second\n",
      "[Step=1050]\tLoss=0.7546\tacc=0.7276\t3805.8 examples/second\n",
      "[Step=1100]\tLoss=0.7613\tacc=0.7249\t3803.6 examples/second\n",
      "[Step=1150]\tLoss=0.7646\tacc=0.7233\t3803.8 examples/second\n",
      "Test Loss=1.0825, Test acc=0.6366\n",
      "Saving...\n",
      "\n",
      "Epoch: 6\n",
      "[Step=1200]\tLoss=0.6043\tacc=0.7881\t2004.4 examples/second\n",
      "[Step=1250]\tLoss=0.6033\tacc=0.7882\t3803.2 examples/second\n",
      "[Step=1300]\tLoss=0.6119\tacc=0.7839\t3818.2 examples/second\n",
      "[Step=1350]\tLoss=0.6210\tacc=0.7799\t3815.5 examples/second\n",
      "Test Loss=1.1817, Test acc=0.6262\n",
      "\n",
      "Epoch: 7\n",
      "[Step=1400]\tLoss=0.4728\tacc=0.8369\t2472.9 examples/second\n",
      "[Step=1450]\tLoss=0.4745\tacc=0.8341\t3813.5 examples/second\n",
      "[Step=1500]\tLoss=0.4798\tacc=0.8298\t3812.3 examples/second\n",
      "[Step=1550]\tLoss=0.4914\tacc=0.8255\t3808.9 examples/second\n",
      "Test Loss=1.1881, Test acc=0.6423\n",
      "Saving...\n",
      "\n",
      "Epoch: 8\n",
      "[Step=1600]\tLoss=0.3551\tacc=0.8756\t2014.0 examples/second\n",
      "[Step=1650]\tLoss=0.3647\tacc=0.8713\t3799.1 examples/second\n",
      "[Step=1700]\tLoss=0.3676\tacc=0.8699\t3813.2 examples/second\n",
      "[Step=1750]\tLoss=0.3795\tacc=0.8654\t3815.5 examples/second\n",
      "Test Loss=1.2855, Test acc=0.6435\n",
      "Saving...\n",
      "\n",
      "Epoch: 9\n",
      "[Step=1800]\tLoss=0.2726\tacc=0.9059\t2005.6 examples/second\n",
      "[Step=1850]\tLoss=0.2704\tacc=0.9040\t3816.3 examples/second\n",
      "[Step=1900]\tLoss=0.2760\tacc=0.9015\t3810.7 examples/second\n",
      "[Step=1950]\tLoss=0.2823\tacc=0.8988\t3813.4 examples/second\n",
      "Test Loss=1.5808, Test acc=0.6188\n",
      "\n",
      "Epoch: 10\n",
      "[Step=2000]\tLoss=0.1821\tacc=0.9407\t2482.6 examples/second\n",
      "[Step=2050]\tLoss=0.1564\tacc=0.9512\t3800.4 examples/second\n",
      "[Step=2100]\tLoss=0.1451\tacc=0.9551\t3811.7 examples/second\n",
      "[Step=2150]\tLoss=0.1380\tacc=0.9578\t3809.2 examples/second\n",
      "Test Loss=1.3417, Test acc=0.6691\n",
      "Saving...\n",
      "\n",
      "Epoch: 11\n",
      "[Step=2200]\tLoss=0.0857\tacc=0.9800\t2032.3 examples/second\n",
      "[Step=2250]\tLoss=0.0899\tacc=0.9777\t3760.7 examples/second\n",
      "[Step=2300]\tLoss=0.0877\tacc=0.9776\t3812.8 examples/second\n",
      "[Step=2350]\tLoss=0.0848\tacc=0.9786\t3804.4 examples/second\n",
      "Test Loss=1.3899, Test acc=0.6684\n",
      "\n",
      "Epoch: 12\n",
      "[Step=2400]\tLoss=0.0654\tacc=0.9861\t2484.5 examples/second\n",
      "[Step=2450]\tLoss=0.0635\tacc=0.9856\t3809.3 examples/second\n",
      "[Step=2500]\tLoss=0.0628\tacc=0.9853\t3808.0 examples/second\n",
      "Test Loss=1.4406, Test acc=0.6673\n",
      "\n",
      "Epoch: 13\n",
      "[Step=2550]\tLoss=0.0550\tacc=0.9863\t2483.6 examples/second\n",
      "[Step=2600]\tLoss=0.0517\tacc=0.9899\t3798.8 examples/second\n",
      "[Step=2650]\tLoss=0.0501\tacc=0.9907\t3808.8 examples/second\n",
      "[Step=2700]\tLoss=0.0497\tacc=0.9907\t3805.8 examples/second\n",
      "Test Loss=1.4786, Test acc=0.6669\n",
      "\n",
      "Epoch: 14\n",
      "[Step=2750]\tLoss=0.0454\tacc=0.9902\t2480.9 examples/second\n",
      "[Step=2800]\tLoss=0.0423\tacc=0.9918\t3812.0 examples/second\n",
      "[Step=2850]\tLoss=0.0413\tacc=0.9922\t3804.3 examples/second\n",
      "[Step=2900]\tLoss=0.0409\tacc=0.9925\t3795.8 examples/second\n",
      "Test Loss=1.5142, Test acc=0.6709\n",
      "Saving...\n",
      "\n",
      "Epoch: 15\n",
      "[Step=2950]\tLoss=0.0321\tacc=0.9953\t2023.0 examples/second\n",
      "[Step=3000]\tLoss=0.0342\tacc=0.9945\t3804.0 examples/second\n",
      "[Step=3050]\tLoss=0.0343\tacc=0.9945\t3817.5 examples/second\n",
      "[Step=3100]\tLoss=0.0343\tacc=0.9945\t3807.6 examples/second\n",
      "Test Loss=1.5214, Test acc=0.6710\n",
      "Saving...\n",
      "\n",
      "Epoch: 16\n",
      "[Step=3150]\tLoss=0.0329\tacc=0.9953\t2019.7 examples/second\n",
      "[Step=3200]\tLoss=0.0347\tacc=0.9951\t3796.4 examples/second\n",
      "[Step=3250]\tLoss=0.0337\tacc=0.9952\t3812.3 examples/second\n",
      "[Step=3300]\tLoss=0.0338\tacc=0.9948\t3816.9 examples/second\n",
      "Test Loss=1.5255, Test acc=0.6692\n",
      "\n",
      "Epoch: 17\n",
      "[Step=3350]\tLoss=0.0319\tacc=0.9959\t2478.3 examples/second\n",
      "[Step=3400]\tLoss=0.0345\tacc=0.9943\t3810.6 examples/second\n",
      "[Step=3450]\tLoss=0.0331\tacc=0.9947\t3806.7 examples/second\n",
      "[Step=3500]\tLoss=0.0331\tacc=0.9948\t3812.3 examples/second\n",
      "Test Loss=1.5277, Test acc=0.6690\n",
      "\n",
      "Epoch: 18\n",
      "[Step=3550]\tLoss=0.0323\tacc=0.9956\t2481.9 examples/second\n",
      "[Step=3600]\tLoss=0.0323\tacc=0.9951\t3802.7 examples/second\n",
      "[Step=3650]\tLoss=0.0325\tacc=0.9947\t3803.2 examples/second\n",
      "[Step=3700]\tLoss=0.0326\tacc=0.9949\t3810.2 examples/second\n",
      "Test Loss=1.5320, Test acc=0.6672\n",
      "\n",
      "Epoch: 19\n",
      "[Step=3750]\tLoss=0.0335\tacc=0.9947\t2474.4 examples/second\n",
      "[Step=3800]\tLoss=0.0319\tacc=0.9954\t3809.3 examples/second\n",
      "[Step=3850]\tLoss=0.0314\tacc=0.9953\t3808.3 examples/second\n",
      "[Step=3900]\tLoss=0.0314\tacc=0.9955\t3808.3 examples/second\n",
      "Test Loss=1.5396, Test acc=0.6694\n"
     ]
    }
   ],
   "source": [
    "train(vgg_model, 20, batch_size, 0.001, 0.0005, trainloader=trainloader, testloader=testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
