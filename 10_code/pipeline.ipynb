{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from scipy.ndimage import rotate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outstanding Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What transformations should we apply to CIFAR-10 clean data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain CIFAR-10 Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMS\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: should we apply the below transformations?\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "print('==> Preparing data..')\n",
    "trainset = torchvision.datasets.CIFAR10(root='../00_data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=16)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='../00_data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Patch - test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path will be placed left-center\n",
      "Image saved at: ../00_data/test_images/banana-patched.jpeg\n"
     ]
    }
   ],
   "source": [
    "h = 'left'\n",
    "v = 'center'\n",
    "ratio = 3\n",
    "\n",
    "PATCH_PATH = '../00_data/patches/toaster_patch.png'\n",
    "src_img = '../00_data/test_images/banana.jpeg'\n",
    "save_path = '../00_data/test_images/banana-patched.jpeg'\n",
    "\n",
    "mode = {\n",
    "    'h': h,\n",
    "    'v': v\n",
    "}\n",
    "\n",
    "print(f\"Path will be placed {mode['h']}-{mode['v']}\")\n",
    "\n",
    "# map from mode value to a function that returns the correct value position\n",
    "mode_to_value = {\n",
    "    'left': lambda width, path: 0,\n",
    "    'center_h': lambda width, path: width // 2 - path.width // 2,\n",
    "    'center_v': lambda height, path: height // 2 - path.height // 2,\n",
    "    'right': lambda width, path: width - path.width,\n",
    "    'up': lambda height, path: 0,\n",
    "    'down': lambda height, path: height - path.height,\n",
    "}\n",
    "\n",
    "def get_position(mode, image, path):\n",
    "    x = mode_to_value[mode['h'] if mode['h'] != 'center' else 'center_h'](image.width, path)\n",
    "    y = mode_to_value[mode['v'] if mode['v'] != 'center' else 'center_v'](image.height, path)\n",
    "    return x, y\n",
    "\n",
    "patch_image = Image.open(PATCH_PATH)\n",
    "src_image = Image.open(src_img)\n",
    "\n",
    "patch_image = patch_image.resize((src_image.width // ratio, src_image.height // ratio), Image.Resampling.LANCZOS)\n",
    "position = get_position(mode, src_image, patch_image)\n",
    "\n",
    "src_image.paste(patch_image, position, mask = patch_image)\n",
    "src_image.save(save_path)\n",
    "\n",
    "print(f\"Image saved at: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
